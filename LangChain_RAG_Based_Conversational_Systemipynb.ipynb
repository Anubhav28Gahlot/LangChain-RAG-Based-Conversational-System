{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cT4ucNmy9wJ0"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "import os\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Output Parser\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Structured Output Model\n",
        "class MobileReview(BaseModel):\n",
        "    phone_model: str = Field(description=\"Name and model of the phone\")\n",
        "    rating: float = Field(description=\"Overall rating out of 5\")\n",
        "    pros: List[str] = Field(description=\"List of positive aspects\")\n",
        "    cons: List[str] = Field(description=\"List of negative aspects\")\n",
        "    summary: str = Field(description=\"Brief summary of the review\")\n",
        "\n",
        "structured_llm = llm.with_structured_output(MobileReview)\n",
        "\n",
        "# Load Documents\n",
        "def load_documents(folder_path: str) -> List[Document]:\n",
        "    documents = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        if filename.endswith('.pdf'):\n",
        "            loader = PyPDFLoader(file_path)\n",
        "        elif filename.endswith('.docx'):\n",
        "            loader = Docx2txtLoader(file_path)\n",
        "        else:\n",
        "            print(f\"Unsupported file type: {filename}\")\n",
        "            continue\n",
        "        documents.extend(loader.load())\n",
        "    return documents\n",
        "\n",
        "folder_path = \"/content/docs\"\n",
        "documents = load_documents(folder_path)\n",
        "\n",
        "# Split Documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)\n",
        "splits = text_splitter.split_documents(documents)\n",
        "\n",
        "# Create Embeddings\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "document_embeddings = embedding_function.embed_documents([split.page_content for split in splits])\n",
        "\n",
        "# Create Vector Store\n",
        "collection_name = \"my_collection\"\n",
        "vectorstore = Chroma.from_documents(collection_name=collection_name, documents=splits, embedding=embedding_function, persist_directory=\"./chroma_db\")\n",
        "\n",
        "# RAG Chain\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "Question: {question}\n",
        "Answer: \"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "def docs2str(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
        "rag_chain = ({\"context\": retriever | docs2str, \"question\": prompt} | llm | StrOutputParser())\n",
        "\n",
        "# SQLite Database\n",
        "DB_NAME = \"rag_app.db\"\n",
        "\n",
        "def get_db_connection():\n",
        "    conn = sqlite3.connect(DB_NAME)\n",
        "    conn.row_factory = sqlite3.Row\n",
        "    return conn\n",
        "\n",
        "def create_application_logs():\n",
        "    conn = get_db_connection()\n",
        "    conn.execute('''CREATE TABLE IF NOT EXISTS application_logs\n",
        "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    session_id TEXT,\n",
        "    user_query TEXT,\n",
        "    gpt_response TEXT,\n",
        "    model TEXT,\n",
        "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')\n",
        "    conn.close()\n",
        "\n",
        "def insert_application_logs(session_id, user_query, gpt_response, model):\n",
        "    conn = get_db_connection()\n",
        "    conn.execute('INSERT INTO application_logs (session_id, user_query, gpt_response, model) VALUES (?, ?, ?, ?)',\n",
        "                 (session_id, user_query, gpt_response, model))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def get_chat_history(session_id):\n",
        "    conn = get_db_connection()\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('SELECT user_query, gpt_response FROM application_logs WHERE session_id = ? ORDER BY created_at', (session_id,))\n",
        "    messages = [{\"role\": \"human\", \"content\": row['user_query']} for row in cursor.fetchall()]\n",
        "    conn.close()\n",
        "    return messages\n",
        "\n",
        "create_application_logs()\n",
        "\n",
        "# Multi-User Chatbot\n",
        "session_id = str(uuid.uuid4())\n",
        "question = \"What is GreenGrow Innovations?\"\n",
        "chat_history = get_chat_history(session_id)\n",
        "response = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})['answer']\n",
        "insert_application_logs(session_id, question, response, \"gpt-4o-mini\")\n",
        "print(f\"Human: {question}\\nAI: {response}\")\n"
      ]
    }
  ]
}